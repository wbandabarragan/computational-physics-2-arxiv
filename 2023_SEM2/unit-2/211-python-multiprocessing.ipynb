{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing in python\n",
    "\n",
    "The **multiprocessing library** is Python's standard library to support parallel computing using processes.\n",
    "\n",
    "See documentation here:\n",
    "\n",
    "https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first print out the total number of CPUs that on my machine that can be used for parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of CPU cores: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use an example to show you how to use multiple cores in one machine to reduce the time of execution time. \n",
    "\n",
    "### Example 1:\n",
    "\n",
    "Generate $10^7$ random numbers between 0 and 10, and square the number. Store the results in a list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Serial version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random_square # our own module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing the code\n",
    "start = time.time()\n",
    "\n",
    "# Empty  list for results \n",
    "results = []\n",
    "\n",
    "# Loop up to 10^7\n",
    "\n",
    "for i in range(10000000): \n",
    "\n",
    "    results.append(random_square.random_square(i))\n",
    "\n",
    "# Finish timing code\n",
    "end =time.time()\n",
    "\n",
    "print(f'Serial execution time is {end - start} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Parallel version\n",
    "\n",
    "The simplest way to do parallel computing using the multiprocessing is to use the **Pool** class.\n",
    "\n",
    "See documentation:\n",
    "\n",
    "https://superfastpython.com/multiprocessing-pool-map/\n",
    "\n",
    "https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool\n",
    "\n",
    "\n",
    "There are 4 common methods in the class that we may use often, that is:\n",
    "\n",
    "1. **apply**, \n",
    "\n",
    "\n",
    "2. **map**, \n",
    "\n",
    "\n",
    "3. **apply_async** and \n",
    "\n",
    "\n",
    "4. **map_async**.\n",
    "\n",
    "Have a look of the documentation for the differences, and we will only use **map** function below to parallel the above example.\n",
    "\n",
    "The **map(func, iterable)** function takes in two arguments, and apply the function **func** to each element in the **iterable**, and then collect the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Timing the code\n",
    "start = time.time()\n",
    "\n",
    "# Get number of laptop CPUs\n",
    "n_cpu = mp.cpu_count()\n",
    "\n",
    "# Call Pool\n",
    "pool = mp.Pool(processes=n_cpu)\n",
    "\n",
    "# Call pool.map(func, iterable)\n",
    "results = [pool.map(random_square.random_square, range(10000000))]\n",
    "\n",
    "# Finish timing code\n",
    "end = time.time()\n",
    "\n",
    "print(f'Parallel execution time is {end - start} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "\n",
    "- We can see that using the above parallel version of the code, we reduce the run time from 59.18333172798157 s to 30.407769918441772 s. This is a big gain in speed, especially if we have a heavy computation, it will reduce a lot of time by running parallel computing. \n",
    "\n",
    "\n",
    "- The `pool.apply` function is similar except that it can accept more arguments. The `pool.map` and `pool.apply` will lock the main program until all the processes are finished, which is quite useful if we want to obtain results in a particular order for some applications.\n",
    "\n",
    "\n",
    "- In contrast, if we do not need the results in a particular order, we can also use `pool.apply_async` or `pool.map_async`, which will submit all processes at once and retrieve the results as soon as they are finished. Check documentation to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the execution time \n",
    "\n",
    "Let's visualise the execution time changes versus the number of data points using both the serial and parallel version.\n",
    "\n",
    "We will see that until certain point, it is better to use the serial version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial function\n",
    "\n",
    "def serial(n):\n",
    "    \n",
    "    start = time.time()\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n): \n",
    "        results.append(random_square.random_square(i))\n",
    "    \n",
    "    end = time.time()\n",
    "    exec_time = end - start\n",
    "    \n",
    "    return exec_time\n",
    "\n",
    "# Parallel function\n",
    "\n",
    "def parallel(n):\n",
    "    \n",
    "    start = time.time()\n",
    "    n_cpu = mp.cpu_count()\n",
    "\n",
    "    pool = mp.Pool(processes=n_cpu)\n",
    "    \n",
    "    results = [pool.map(random_square.random_square, range(n))]\n",
    "    \n",
    "    end = time.time()\n",
    "    exec_time = end - start\n",
    "    \n",
    "    return exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate numbers in log-space:\n",
    "n_run = np.logspace(1, 7, num = 7)\n",
    "\n",
    "print(n_run)\n",
    "\n",
    "# Call functions for each n_run[i]\n",
    "\n",
    "t_serial = [serial(int(n)) for n in n_run]\n",
    "\n",
    "t_parallel = [parallel(int(n)) for n in n_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_serial)\n",
    "print(t_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 4))\n",
    "\n",
    "plt.plot(n_run, t_serial, '-o', color = \"red\", label = 'serial')\n",
    "plt.plot(n_run, t_parallel, '-o', color = \"green\", label = 'parallel')\n",
    "\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Execution time (s)')\n",
    "plt.xlabel('Number of random points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "We can see from the figure that when the number of data points are small (below 10000), the execution time for the serial version is faster due to the overheads of the parallel version from launching and maintaining the new processes. But after that, we can see clearly the winner be the parallel version. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using joblib\n",
    "\n",
    "\n",
    "In Python, there are also other 3rd party packages that can make the parallel computing easier, especially for some daily tasks.\n",
    "\n",
    "**joblib** is one of them, it provides an easy simple way to do parallel computing (it has many other usages as well). \n",
    "\n",
    "\n",
    "#### See documentation:\n",
    "\n",
    "https://joblib.readthedocs.io/en/latest/index.html\n",
    "\n",
    "First you need to install it by running \n",
    "\n",
    "```python\n",
    "conda install joblib\n",
    "```\n",
    "\n",
    "Or:\n",
    "\n",
    "```python\n",
    "pip install joblib\n",
    "```\n",
    "\n",
    "Let's see how can we run the previous example using this new package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time stamp at the beginning of the execution\n",
    "start = time.time()\n",
    "\n",
    "results = Parallel(n_jobs = 1)(delayed(random_square.random_square)(i) for i in range(1000000))\n",
    "\n",
    "# Time stamp at the end of the execution\n",
    "end = time.time()\n",
    "\n",
    "# Print execution\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.82672882080078\n"
     ]
    }
   ],
   "source": [
    "# Time stamp at the beginning of the execution\n",
    "start = time.time()\n",
    "\n",
    "results = Parallel(n_jobs = 2)(delayed(random_square.random_square)\\\n",
    "          (i) for i in range(1000000))\n",
    "\n",
    "# Time stamp at the end of the execution\n",
    "end = time.time()\n",
    "\n",
    "# Print execution\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the parallel part of the code becomes one line by using the joblib library, which is very convenient.\n",
    "\n",
    "\n",
    "The **Parallel** is a helper class that essentially provides a convenient interface for the **multiprocessing** module we saw before.\n",
    "\n",
    "The **delayed** is used to capture the arguments of the target function, in this case, the **random_square**. We run the above code with 2 cores.\n",
    "\n",
    "### Notes on usage:\n",
    "\n",
    "If you want to use all of the computational power on your machine. You can use all cores on your machine by setting *n\\_jobs=-1*.\n",
    "\n",
    "\n",
    "If you set it to -2, all CPUs but one are used. \n",
    "\n",
    "\n",
    "Besides, you can turn on the **verbose** argument to output the status messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360456 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000000 out of 1000000 | elapsed:   20.1s finished\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=-1, verbose=1)(delayed(random_square.random_square)(i) for i in range(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backends\n",
    "\n",
    "There are multiple backends in **joblib**, which means using different ways to do the parallel computing.\n",
    "\n",
    "If you set the backend as **multiprocessing**, this is actually creating, under the hood, a multiprocessing pool that uses separate Python woker processes to execute tasks concurrently on separate cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 786424 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000000 out of 1000000 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=-1, backend='multiprocessing', verbose=1)\\\n",
    "          (delayed(random_square.random_square)(i) for i in range(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
